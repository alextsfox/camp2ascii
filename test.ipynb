{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475dec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from camp2ascii import camp2ascii\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6a12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alextsfox/git-repos/camp2ascii/camp2ascii/pipeline.py:72: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  timestamps[i*header.data_nlines:(i+1)*header.data_nlines] = np.arange(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "arange: cannot compute length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m out_dir.iterdir():\n\u001b[32m     13\u001b[39m     f.unlink() \u001b[38;5;28;01mif\u001b[39;00m f.is_file() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m out_files = \u001b[43mcamp2ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m my_tob3 = pd.read_csv(out_files[\u001b[32m2\u001b[39m], skiprows=[\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m], parse_dates=[\u001b[33m\"\u001b[39m\u001b[33mTIMESTAMP\u001b[39m\u001b[33m\"\u001b[39m], index_col=\u001b[33m\"\u001b[39m\u001b[33mTIMESTAMP\u001b[39m\u001b[33m\"\u001b[39m, na_values=\u001b[33m\"\u001b[39m\u001b[33mNAN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m ref_tob3 = pd.read_csv(Path(\u001b[33m\"\u001b[39m\u001b[33mtests/cc-basic/TOA5_TOB3_ring2.dat\u001b[39m\u001b[33m\"\u001b[39m), skiprows=[\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m], parse_dates=[\u001b[33m\"\u001b[39m\u001b[33mTIMESTAMP\u001b[39m\u001b[33m\"\u001b[39m], index_col=\u001b[33m\"\u001b[39m\u001b[33mTIMESTAMP\u001b[39m\u001b[33m\"\u001b[39m, na_values=\u001b[33m\"\u001b[39m\u001b[33mNAN\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/camp2ascii/camp2ascii/camp2ascii.py:162\u001b[39m, in \u001b[36mcamp2ascii\u001b[39m\u001b[34m(input_files, output_dir, n_invalid, pbar, store_record_numbers, store_timestamp, time_interval, timedate_filenames, contiguous_timeseries)\u001b[39m\n\u001b[32m    148\u001b[39m contiguous_timeseries = contiguous_timeseries\n\u001b[32m    150\u001b[39m cfg = Config(\n\u001b[32m    151\u001b[39m     input_files=input_files,\n\u001b[32m    152\u001b[39m     out_dir=out_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m     contiguous_timeseries=contiguous_timeseries,\n\u001b[32m    160\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m final_output_paths = \u001b[43mexecute_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final_output_paths\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/camp2ascii/camp2ascii/pipeline.py:133\u001b[39m, in \u001b[36mexecute_config\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m    131\u001b[39m output_paths = []\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m cfg.input_files:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     df, header = \u001b[43mprocess_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cfg.timedate_filenames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m df.index.name == \u001b[33m\"\u001b[39m\u001b[33mTIMESTAMP\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    135\u001b[39m         out_path = Path(cfg.out_dir) / (\u001b[33m\"\u001b[39m\u001b[33mTOA5_\u001b[39m\u001b[33m\"\u001b[39m + path.stem + \u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m + df.index.min().strftime(cfg.timedate_filenames) + path.suffix)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/camp2ascii/camp2ascii/pipeline.py:116\u001b[39m, in \u001b[36mprocess_file\u001b[39m\u001b[34m(path, n_invalid, pbar)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# decode the intermediate header and footer outputs\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m header.file_type \u001b[38;5;129;01min\u001b[39;00m (FileType.TOB3, FileType.TOB2):\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# produce the footers for debugging purposes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     timestamps, records, footers = \u001b[43mcompute_timestamps_and_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheaders_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfooters_raw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnlines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mTIMESTAMP\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(timestamps, unit=\u001b[33m'\u001b[39m\u001b[33mns\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    118\u001b[39m     df[\u001b[33m\"\u001b[39m\u001b[33mRECORD\u001b[39m\u001b[33m\"\u001b[39m] = records\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git-repos/camp2ascii/camp2ascii/pipeline.py:72\u001b[39m, in \u001b[36mcompute_timestamps_and_records\u001b[39m\u001b[34m(headers_raw, footers_raw, valid_rows, header, nframes, nlines)\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     71\u001b[39m         beg_record = i*header.data_nlines\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     timestamps[i*header.data_nlines:(i+\u001b[32m1\u001b[39m)*header.data_nlines] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeg_timestamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeg_timestamp\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_nlines\u001b[49m\u001b[43m*\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrec_intvl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m1_000_000_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint64\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrec_intvl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m1_000_000_000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint64\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     records[i*header.data_nlines:(i+\u001b[32m1\u001b[39m)*header.data_nlines] = np.arange(beg_record, beg_record + header.data_nlines)\n\u001b[32m     79\u001b[39m records = records[valid_rows]\n",
      "\u001b[31mValueError\u001b[39m: arange: cannot compute length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from camp2ascii import camp2ascii\n",
    "\n",
    "in_dir = Path(\"tests/raw\")\n",
    "\n",
    "out_dir = Path(\"tests/c2a-basic\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "for f in out_dir.iterdir():\n",
    "    f.unlink() if f.is_file() else None\n",
    "out_files = camp2ascii(in_dir, out_dir)\n",
    "\n",
    "my_tob3 = pd.read_csv(out_files[2], skiprows=[0, 2, 3], parse_dates=[\"TIMESTAMP\"], index_col=\"TIMESTAMP\", na_values=\"NAN\")\n",
    "ref_tob3 = pd.read_csv(Path(\"tests/cc-basic/TOA5_TOB3_ring2.dat\"), skiprows=[0, 2, 3], parse_dates=[\"TIMESTAMP\"], index_col=\"TIMESTAMP\", na_values=\"NAN\")\n",
    "my_tob3.shape, ref_tob3.shape\n",
    "\n",
    "my_tob3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9028bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out_dir = Path(\"tests/c2a-timedate-filenames\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "for f in out_dir.iterdir():\n",
    "    f.unlink() if f.is_file() else None\n",
    "camp2ascii(in_dir, out_dir, timedate_filenames=2)\n",
    "\n",
    "in_dir = Path(\"tests/raw-2\")\n",
    "out_dir = Path(\"tests/c2a-time-split-1\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "for f in out_dir.iterdir():\n",
    "    f.unlink() if f.is_file() else None\n",
    "camp2ascii(in_dir, out_dir, time_interval=\"1m\")\n",
    "\n",
    "out_dir = Path(\"tests/c2a-time-split-2\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "for f in out_dir.iterdir():\n",
    "    f.unlink() if f.is_file() else None\n",
    "camp2ascii(in_dir, out_dir, time_interval=\"3m\", timedate_filenames=1, contiguous_timeseries=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ec-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
