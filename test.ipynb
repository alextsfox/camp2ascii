{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cecf5c5e",
   "metadata": {},
   "source": [
    "Valid:\n",
    "* TOB3_long2\n",
    "* TOB3_long3\n",
    "* TOB3_long4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e6a12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  31%|███▏      | 221k/708k [00:00<00:00, 1.08MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  61%|██████    | 430k/708k [00:00<00:00, 1.04MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files:  87%|████████▋ | 615k/708k [00:00<00:00, 954kB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 865kB [00:00, 999kB/s]                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 708k/708k [00:01<00:00, 650kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huh?\n",
      "huh?\n",
      "huh?\n",
      "huh?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from unittest import TestCase\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import camp2ascii.formats as fmt\n",
    "from camp2ascii import camp2ascii\n",
    "\n",
    "fmt.REPAIR_MISALIGNED_MINOR_FRAMES = False\n",
    "\n",
    "\n",
    "parent = Path(\"/home/alextsfox/git-repos/camp2ascii/tests\")\n",
    "\n",
    "in_dir = parent / \"raw\"\n",
    "\n",
    "out_dir = parent / \"c2a\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# fig, axs = plt.subplots(ceil(20/2), 2, figsize=(12, 15), sharex=True)\n",
    "try:\n",
    "    out_files = camp2ascii(in_dir, out_dir, pbar=True, verbose=3)\n",
    "    for f in out_files:\n",
    "        file_type = re.search(r\"TOB\\d\", f.name).group(0)\n",
    "\n",
    "        my_tob3 = pd.read_csv(f, skiprows=[0, 2, 3], na_values=[\"NAN\", '\"NAN\"'])\n",
    "        my_tob3[\"TIMESTAMP\"] = pd.to_datetime(my_tob3[\"TIMESTAMP\"], format=\"ISO8601\")\n",
    "\n",
    "        ref_file = list((out_dir.parent / \"cc\").glob(f\"*{f.stem}*\"))[0]\n",
    "        ref_tob3 = pd.read_csv(ref_file, skiprows=[0, 2, 3], na_values=[\"NAN\", '\"NAN\"'])\n",
    "        ref_tob3[\"TIMESTAMP\"] = pd.to_datetime(ref_tob3[\"TIMESTAMP\"], format=\"ISO8601\")\n",
    "\n",
    "        if \"temp_TMx(1)\" in ref_tob3.columns:\n",
    "            ref_tob3[\"temp_TMx(1)\"] = pd.to_datetime(ref_tob3[\"temp_TMx(1)\"], format=\"ISO8601\")\n",
    "            my_tob3[\"temp_TMx(1)\"] = pd.to_datetime(my_tob3[\"temp_TMx(1)\"], format=\"ISO8601\")\n",
    "        \n",
    "        for col in ref_tob3.columns:\n",
    "            if col in {\"TIMESTAMP\", \"temp_TMx(1)\"}:\n",
    "                ref_tob3[col] = ref_tob3[col].astype(np.int64)\n",
    "                my_tob3[col] = my_tob3[col].astype(np.int64)\n",
    "            ref_tob3[col] = ref_tob3[col].astype(np.float64)\n",
    "            my_tob3[col] = my_tob3[col].astype(np.float64)\n",
    "\n",
    "        ref_tob3 = ref_tob3.set_index(\"RECORD\")\n",
    "        my_tob3 = my_tob3.set_index(\"RECORD\")\n",
    "\n",
    "\n",
    "        common_idx = ref_tob3.index.union(my_tob3.index)\n",
    "        if file_type == \"TOB3\" and ref_tob3[\"TIMESTAMP\"].diff().diff().abs().max() > 1e5:  # 100us\n",
    "            common_idx = ref_tob3.index.intersection(my_tob3.index)\n",
    "        ref_tob3 = ref_tob3.loc[common_idx].sort_index()\n",
    "        my_tob3 = my_tob3.loc[common_idx].sort_index()\n",
    "\n",
    "        print(np.allclose(ref_tob3, my_tob3, equal_nan=True))\n",
    "finally:\n",
    "    for f in out_files:\n",
    "        f.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4de83654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_footer(footer_bytes: bytes):\n",
    "    content = int.from_bytes(footer_bytes, \"little\", signed=True)\n",
    "    return dict(\n",
    "        offset = content & 0x7FF,\n",
    "        file_mark = bool((content >> 11) & 0x1),\n",
    "        ring_mark = bool((content >> 12) & 0x1),\n",
    "        empty_frame = bool((content >> 13) & 0x1),\n",
    "        minor_frame = bool((content >> 14) & 0x1),\n",
    "        validation = (content >> 16) & 0xFFFF,\n",
    "    )\n",
    "def parse_header(header_bytes: bytes):\n",
    "    FRAME_HEADER_DTYPE = np.dtype([('seconds', '<i4'), ('subseconds', '<i4'), ('beg_record', '<i4')])\n",
    "    return np.frombuffer(header_bytes, dtype=FRAME_HEADER_DTYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c14e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_minor_frames(input_buffer: bytes, offset: int, frame_nbytes: int):\n",
    "    \"\"\"A minor frame flag indicates that the frame is split up into multiple sub-frames.\n",
    "    The offset of the footer of each sub-frame gives the position of it's start byte within the major frame.\n",
    "    The last sub-frame is always corrupted, so we start from the second to last one and work our way backwards until we end up at the start of the major frame.\n",
    "    We then put the sub-frames in chronological order.\n",
    "\n",
    "    The input_buffer should start at the very end of the major frame.\n",
    "    \"\"\"\n",
    "    # the last minor frame is always corrupted, so we rewind to the previous one\n",
    "    f.seek(-offset - 4, 1)\n",
    "    minor_frame_nbytes = parse_footer(f.read(4))[\"offset\"]\n",
    "\n",
    "    minor_frame_footers_raw = []\n",
    "    minor_frame_headers_raw = []\n",
    "    minor_frame_data_raw = []\n",
    "    while f.tell() > start:\n",
    "        # go back to the head of the minor frame we sit at the foot of\n",
    "        f.seek(-minor_frame_nbytes, 1)\n",
    "        minor_frame_headers_raw.append(f.read(12))\n",
    "        minor_frame_data_raw.append(f.read(minor_frame_nbytes - 16))\n",
    "        minor_frame_footers_raw.append(f.read(4))\n",
    "        \n",
    "        # determine the sizee of the previous minor frame by reading its footer\n",
    "        f.seek(-minor_frame_nbytes-4, 1)\n",
    "        minor_frame_nbytes = parse_footer(f.read(4))[\"offset\"]\n",
    "\n",
    "        print(parse_header(minor_frame_headers_raw[-1]), parse_footer(minor_frame_footers_raw[-1]), len(minor_frame_data_raw[-1])+16)\n",
    "    \n",
    "    # put frames in chronological order\n",
    "    minor_frame_headers_raw = minor_frame_headers_raw[::-1]\n",
    "    minor_frame_data_raw = minor_frame_data_raw[::-1]\n",
    "    minor_frame_footers_raw = minor_frame_footers_raw[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "821c898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1140440850, 9250, 2102)] {'offset': 108, 'file_mark': False, 'ring_mark': False, 'empty_frame': False, 'minor_frame': True, 'validation': 46432} 1008\n",
      "[(1140440850, 9600, 2108)] {'offset': 140, 'file_mark': False, 'ring_mark': False, 'empty_frame': False, 'minor_frame': False, 'validation': 46432} 140\n",
      "[(1140440850, 9250, 2102)] {'offset': 760, 'file_mark': False, 'ring_mark': False, 'empty_frame': False, 'minor_frame': False, 'validation': 46432} 760\n",
      "\n",
      "[(1140440850, 9250, 2102)]\n",
      "b\"64291\\x00\\x00\\x00the quick brown fox jumped over the lazy dog\\x00\\x00\\x00\\x00why'd you leave the orange dish rag in the sink? It'll get mold!\\x00\\x00\\x00\\x0064291\\x00\\x00\\x00the quick brown fox jumped over the lazy dog\\x00\\x00\\x00\\x00why'd you leave the orange dish rag in the sink? It'll get mold!\\x00\\x00\\x00\\x0064291\\x00\\x00\\x00the quick brown fox jumped over the lazy dog\\x00\\x00\\x00\\x00why'd you leave the orange dish rag in the sink? It'll get mold!\\x00\\x00\\x00\\x0064291\\x00\\x00\\x00the quick brown fox jumped over the lazy dog\\x00\\x00\\x00\\x00why'd you leave the orange dish rag in the sink? It'll get mold!\\x00\\x00\\x00\\x0064291\\x00\\x00\\x00the quick brown fox jumped over the lazy dog\\x00\\x00\\x00\\x00why'd you leave the orange dish rag in the sink? It'll get mold!\\x00\\x00\\x00\\x0064291\\x00\\x00\\x00the quick brown fox jumped over the lazy dog\\x00\\x00\\x00\\x00why'd you leave the orange dish rag in the sink? It'll get mold!\\x00\\x00\\x00\\x00\"\n",
      "{'offset': 760, 'file_mark': False, 'ring_mark': False, 'empty_frame': False, 'minor_frame': False, 'validation': 46432}\n",
      "\n",
      "[(1140440850, 9600, 2108)]\n",
      "b\"64291\\x00\\x00\\x00the quick brown fox jumped over the lazy dog\\x00\\x00\\x00\\x00why'd you leave the orange dish rag in the sink? It'll get mold!\\x00\\x00\\x00\\x00\"\n",
      "{'offset': 140, 'file_mark': False, 'ring_mark': False, 'empty_frame': False, 'minor_frame': False, 'validation': 46432}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1008\n",
    "import numpy as np\n",
    "\n",
    "with open(\"tests/partial_frame_test/raw/TOB3_partial1.dat\", \"rb\") as f:\n",
    "    # good_bytes = f.read(1008)\n",
    "    f.seek(0x5c90)\n",
    "    bad_bytes = f.read(1008)\n",
    "\n",
    "    # second minor frame starts at 760\n",
    "\n",
    "    # try this: get footer offset, then rewind by offset and parse that frame\n",
    "    # then rewind to the footer of the previous frame and parse that frame, until we reach the first frame we encountered.\n",
    "    # we KNOW there is a good frame starting at 760 bytes into the bad_bytes\n",
    "\n",
    "    frame_nbytes = 1008\n",
    "    data_nbytes = 1008 - 4 - 12\n",
    "    data_nlines = 8\n",
    "    line_nbytes = 124\n",
    "\n",
    "    bad_footer = parse_footer(bad_bytes[-4:])\n",
    "    bad_header = parse_header(bad_bytes[:12])\n",
    "    bad_data = bad_bytes[12:-4]\n",
    "\n",
    "    print(bad_header, bad_footer, len(bad_data)+16)\n",
    "    if bad_footer[\"offset\"] != 0:\n",
    "        start = f.tell() - frame_nbytes\n",
    "        \n",
    "        # the last minor frame is always corrupted, so we rewind to the previous one\n",
    "        f.seek(-bad_footer[\"offset\"] - 4, 1)\n",
    "        minor_frame_nbytes = parse_footer(f.read(4))[\"offset\"]\n",
    "\n",
    "        minor_frame_footers_raw = []\n",
    "        minor_frame_headers_raw = []\n",
    "        minor_frame_data_raw = []\n",
    "        while f.tell() > start:\n",
    "            # go back to the head of the minor frame we sit at the foot of\n",
    "            f.seek(-minor_frame_nbytes, 1)\n",
    "            minor_frame_headers_raw.append(f.read(12))\n",
    "            minor_frame_data_raw.append(f.read(minor_frame_nbytes - 16))\n",
    "            minor_frame_footers_raw.append(f.read(4))\n",
    "            \n",
    "            # determine the sizee of the previous minor frame by reading its footer\n",
    "            f.seek(-minor_frame_nbytes-4, 1)\n",
    "            minor_frame_nbytes = parse_footer(f.read(4))[\"offset\"]\n",
    "\n",
    "            print(parse_header(minor_frame_headers_raw[-1]), parse_footer(minor_frame_footers_raw[-1]), len(minor_frame_data_raw[-1])+16)\n",
    "        \n",
    "        # put frames in chronological order\n",
    "        minor_frame_headers_raw = minor_frame_headers_raw[::-1]\n",
    "        minor_frame_data_raw = minor_frame_data_raw[::-1]\n",
    "        minor_frame_footers_raw = minor_frame_footers_raw[::-1]\n",
    "\n",
    "        print()\n",
    "        for h, d, f in zip(minor_frame_headers_raw, minor_frame_data_raw, minor_frame_footers_raw):\n",
    "            print(parse_header(h))\n",
    "            print(d)\n",
    "            print(parse_footer(f))\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
